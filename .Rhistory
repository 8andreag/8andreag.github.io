ggplot(data = student_G123,
mapping = aes(
x = Medu,
fill = famsup)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Mother's Education", x = "Education Level", y = "Count")
ggplot(student_G123,
mapping = aes(
x = Fedu,
y = Grade,
color = famsup
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
facet_wrap(~ Term) +
labs(title = "Father's Education vs. Final Grades",
x = "Father's Education Level",
y = "Final Grades")
ggplot(student_G123,
mapping = aes(
x = Medu,
y = Grade,
color = famsup
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
facet_wrap(~ Term) +
labs(title = "Mother's Education vs. Final Grades",
x = "Mother's Education Level",
y = "Final Grades")
ggplot(data = student_G123,
mapping = aes(
x = studytime,
y = Grade,
fill = Pstatus
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Study Times Across Terms",
x = "Study Time",
y = "Grade")
student_G123 |>
group_by(Pstatus, Term) |>
summarise(
num_total = n(),
min = min(Grade, na.rm = TRUE),
median = median(Grade, na.rm = TRUE),
max = max(Grade, na.rm = TRUE),
mean = mean(Grade, na.rm = TRUE),
sd = sd(Grade, na.rm = TRUE)
)
student_train |>
group_by(guardian) |>
summarise(mean_G3 = mean(G3, na.rm = TRUE),
count = n())
ggplot(student, aes(x = guardian, fill = guardian)) +
geom_bar() +
labs(title = "Primary Caregiver Distribution",
x = "Guardian", y = "Count")
library(ggplot2)
ggplot(student, aes(x = G1)) +
geom_histogram(binwidth = 1, fill = "pink", color = "black") +
labs(title = "Distribution of G1 (First Trimester Grades)", x = "G1", y = "Count")
ggplot(student, aes(x = G2)) +
geom_histogram(binwidth = 1, fill = "lavender", color = "black") +
labs(title = "Distribution of G2 (Second Trimester Grades)", x = "G2", y = "Count")
ggplot(student, aes(x = G3)) +
geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
labs(title = "Distribution of G3 (Final Grades)", x = "G3", y = "Count")
cor(student[, c("G1", "G2", "G3")])
# Create a recipe for preprocessing
student_pca_recipe <- recipe(G3 ~ ., data = student_train) |>
step_dummy(all_nominal_predictors()) |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors())
library(ggplot2)
# Create a grid of PC1 and PC2 values
grid <- expand.grid(
PC1 = seq(min(pca_scores$PC1), max(pca_scores$PC1), length.out = 100),
PC2 = seq(min(pca_scores$PC2), max(pca_scores$PC2), length.out = 100)
)
# Predict class for each point on the grid
grid$predicted <- predict(multinom_model, newdata = grid)
ggplot() +
geom_tile(data = grid, aes(x = PC1, y = PC2, fill = predicted), alpha = 0.3) +
geom_point(data = pca_scores, aes(x = PC1, y = PC2, color = G3_category), size = 2) +
scale_fill_manual(values = c("low" = "red", "medium" = "gray", "high" = "lightgreen")) +
scale_color_manual(values = c("low" = "red", "medium" = "gray", "high" = "lightgreen")) +
labs(title = "Multinomial Logistic Regression Decision Boundaries",
subtitle = "Predicted Grade Categories in PC1 vs. PC2 Space",
x = "PC1", y = "PC2", fill = "Predicted", color = "Actual")
# test set
student_test <- student_test |>
mutate(G3_category = case_when(
G3 < 10 ~ "low",
G3 >= 10 & G3 < 15 ~ "medium",
G3 >= 15 ~ "high"
))
student_pca_recipe <- recipe(G3_category ~ ., data = student_train) |>
update_role(G3, new_role = "id") |>
step_dummy(all_nominal_predictors()) |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors())
here::i_am("437proj.qmd")
#| label: load packages
#| message: false
#| warning: false
library(here)
library(readr)
library(dplyr)
library(ggplot2)
library(rsample)
library(tidymodels)
library(tidyverse)
library(recipes) # don't need the rest of tidymodels
library(naniar)
library(softImpute)
library(broom)
library(mice)
#| label: import data
#| warning: false
data <- readr::read_csv(here::here("student-por.csv"))
data
vis_miss(data[,1:33]) # default row and column order
student <- data |>
select(Pstatus, Fedu, Medu, guardian, studytime, famsup, G1, G2, G3)
student <- student |>
mutate(
Pstatus = as.factor(Pstatus),
guardian = as.factor(guardian),
studytime = as.factor(studytime),
famsup = as.factor(famsup)
)
student
set.seed(123)
student_split <- initial_split(student, prop = 0.80)  #splitting data  (random sample, 80%)
student_train <- training(student_split)
student_test <- testing(student_split)
student_train |>
miss_var_summary()
table(student_train$famsup)
ggplot(data = student_train,
mapping = aes(
x = famsup,
fill = famsup
)
) +
geom_bar() +
labs(title = "Distribution of Family Support", x = "Family Support", y = "Count")
student_G123 <- student_train |>
pivot_longer(cols = c(G1, G2, G3),
names_to = "Term",
values_to = "Grade")
ggplot(student_G123,
mapping = aes(
x = famsup,
y = Grade,
fill = famsup
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Family Support Across Terms",
x = "Family Support",
y = "Grade")
means_by_group <- student_G123 |>
group_by(Term, famsup) |>
summarise(mean_grade = mean(Grade, na.rm = TRUE), .groups = "drop")
means_by_group
ggplot(data = student_G123,
mapping = aes(
x = Grade,
fill = famsup)
) +
geom_histogram(binwidth = 1) +
facet_grid(
rows = vars(famsup), cols = vars(Term)
)
student_train |>
group_by(Fedu) |>
summarise(mean_G3 = mean(G3, na.rm = TRUE),
count = n())
ggplot(data = student_G123,
mapping = aes(
x = Fedu,
fill = famsup
)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Father's Education", x = "Education Level", y = "Count")
student_train |>
group_by(Medu) |>
summarise(mean_G3 = mean(G3, na.rm = TRUE),
count = n())
ggplot(data = student_G123,
mapping = aes(
x = Medu,
fill = famsup)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Mother's Education", x = "Education Level", y = "Count")
ggplot(student_G123,
mapping = aes(
x = Fedu,
y = Grade,
color = famsup
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
facet_wrap(~ Term) +
labs(title = "Father's Education vs. Final Grades",
x = "Father's Education Level",
y = "Final Grades")
ggplot(student_G123,
mapping = aes(
x = Medu,
y = Grade,
color = famsup
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
facet_wrap(~ Term) +
labs(title = "Mother's Education vs. Final Grades",
x = "Mother's Education Level",
y = "Final Grades")
ggplot(data = student_G123,
mapping = aes(
x = studytime,
y = Grade,
fill = Pstatus
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Study Times Across Terms",
x = "Study Time",
y = "Grade")
student_G123 |>
group_by(Pstatus, Term) |>
summarise(
num_total = n(),
min = min(Grade, na.rm = TRUE),
median = median(Grade, na.rm = TRUE),
max = max(Grade, na.rm = TRUE),
mean = mean(Grade, na.rm = TRUE),
sd = sd(Grade, na.rm = TRUE)
)
student_train |>
group_by(guardian) |>
summarise(mean_G3 = mean(G3, na.rm = TRUE),
count = n())
ggplot(student, aes(x = guardian, fill = guardian)) +
geom_bar() +
labs(title = "Primary Caregiver Distribution",
x = "Guardian", y = "Count")
library(ggplot2)
ggplot(student, aes(x = G1)) +
geom_histogram(binwidth = 1, fill = "pink", color = "black") +
labs(title = "Distribution of G1 (First Trimester Grades)", x = "G1", y = "Count")
ggplot(student, aes(x = G2)) +
geom_histogram(binwidth = 1, fill = "lavender", color = "black") +
labs(title = "Distribution of G2 (Second Trimester Grades)", x = "G2", y = "Count")
ggplot(student, aes(x = G3)) +
geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
labs(title = "Distribution of G3 (Final Grades)", x = "G3", y = "Count")
cor(student[, c("G1", "G2", "G3")])
# Create a recipe for preprocessing
student_pca_recipe <- recipe(G3 ~ ., data = student_train) |>
step_dummy(all_nominal_predictors()) |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors())
#This step learns everything needed to transform the training data.
student_pca_prep <- student_pca_recipe |>
prep() #prepares the recipe by estimating means and standard deviations
student_pca_baked <- bake(student_pca_prep, new_data = NULL) |> #bake() applies the recipe (centered, scaled, dummified) to the training data.
select(-G3)
#new_data = NULL means it’s applying the recipe to the original training set used in prep().
# Apply PCA
student_pca_model <- prcomp(student_pca_baked, center = TRUE, scale. = TRUE)
#Runs PCA on preprocessed dataset using prcomp().
#center = TRUE and scale. = TRUE are redundant here but it doesn’t hurt.
student_pca_model
student_pca_pve <- student_pca_model |>
tidy(matrix = "pcs")
ggplot(student_pca_pve,
aes(x = PC,
y = percent)) +
geom_point() +
geom_line() +
labs(x = "Number of PCs",
y = "Proportion of Variance Explained")
ggplot(student_pca_pve,
aes(x = PC,
y = cumulative)) +
geom_point() +
geom_line() +
geom_hline(yintercept = 0.8, color = "red") +
labs(x = "Number of PCs",
y = "Cumulative Proportion of Variance Explained")
explained_var <- summary(student_pca_model)$importance[3, ]
which(explained_var >= 0.80)[1]
summary(student_pca_model)$importance
set.seed(123)
biplot(student_pca_model,
scale = 0,
cex = 0.9, # Shrinks text size
main = "Biplot of Student PCA")
rownames(student_pca_model$x) <- rownames(student_pca_baked)
random_rows <- sample(nrow(student_pca_model$x), 100) #100 obervations
biplot(
x = student_pca_model$x[random_rows,],
y = student_pca_model$rotation
)
loadings <- as.data.frame(student_pca_model$rotation[, 1:2])
loadings$var <- rownames(loadings)
ggplot(loadings, aes(x = PC1, y = PC2, label = var)) +
geom_segment(aes(x = 0, y = 0, xend = PC1, yend = PC2),
arrow = arrow(length = unit(0.2, "cm")), color = "blue") +
geom_text(vjust = 1.2, size = 1.95) +
xlim(-1, 1) + ylim(-1, 1) +
labs(title = "Variable Loadings on PC1 and PC2")
here::i_am("437proj.qmd")
#| label: load packages
#| message: false
#| warning: false
library(here)
library(readr)
library(dplyr)
library(ggplot2)
library(rsample)
library(tidymodels)
library(tidyverse)
library(recipes) # don't need the rest of tidymodels
library(naniar)
library(softImpute)
library(broom)
library(mice)
#| label: import data
#| warning: false
data <- readr::read_csv(here::here("student-por.csv"))
data
vis_miss(data[,1:33]) # default row and column order
student <- data |>
select(Pstatus, Fedu, Medu, guardian, studytime, famsup, G1, G2, G3)
student <- student |>
mutate(
Pstatus = as.factor(Pstatus),
guardian = as.factor(guardian),
studytime = as.factor(studytime),
famsup = as.factor(famsup)
)
student
set.seed(123)
student_split <- initial_split(student, prop = 0.80)  #splitting data  (random sample, 80%)
student_train <- training(student_split)
student_test <- testing(student_split)
student_train |>
miss_var_summary()
table(student_train$famsup)
ggplot(data = student_train,
mapping = aes(
x = famsup,
fill = famsup
)
) +
geom_bar() +
labs(title = "Distribution of Family Support", x = "Family Support", y = "Count")
student_G123 <- student_train |>
pivot_longer(cols = c(G1, G2, G3),
names_to = "Term",
values_to = "Grade")
ggplot(student_G123,
mapping = aes(
x = famsup,
y = Grade,
fill = famsup
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Family Support Across Terms",
x = "Family Support",
y = "Grade")
means_by_group <- student_G123 |>
group_by(Term, famsup) |>
summarise(mean_grade = mean(Grade, na.rm = TRUE), .groups = "drop")
means_by_group
ggplot(data = student_G123,
mapping = aes(
x = Grade,
fill = famsup)
) +
geom_histogram(binwidth = 1) +
facet_grid(
rows = vars(famsup), cols = vars(Term)
)
student_train |>
group_by(Fedu) |>
summarise(mean_G3 = mean(G3, na.rm = TRUE),
count = n())
ggplot(data = student_G123,
mapping = aes(
x = Fedu,
fill = famsup
)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Father's Education", x = "Education Level", y = "Count")
student_train |>
group_by(Medu) |>
summarise(mean_G3 = mean(G3, na.rm = TRUE),
count = n())
ggplot(data = student_G123,
mapping = aes(
x = Medu,
fill = famsup)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Mother's Education", x = "Education Level", y = "Count")
ggplot(student_G123,
mapping = aes(
x = Fedu,
y = Grade,
color = famsup
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
facet_wrap(~ Term) +
labs(title = "Father's Education vs. Final Grades",
x = "Father's Education Level",
y = "Final Grades")
ggplot(student_G123,
mapping = aes(
x = Medu,
y = Grade,
color = famsup
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
facet_wrap(~ Term) +
labs(title = "Mother's Education vs. Final Grades",
x = "Mother's Education Level",
y = "Final Grades")
ggplot(data = student_G123,
mapping = aes(
x = studytime,
y = Grade,
fill = Pstatus
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Study Times Across Terms",
x = "Study Time",
y = "Grade")
student_G123 |>
group_by(Pstatus, Term) |>
summarise(
num_total = n(),
min = min(Grade, na.rm = TRUE),
median = median(Grade, na.rm = TRUE),
max = max(Grade, na.rm = TRUE),
mean = mean(Grade, na.rm = TRUE),
sd = sd(Grade, na.rm = TRUE)
)
student_train |>
group_by(guardian) |>
summarise(mean_G3 = mean(G3, na.rm = TRUE),
count = n())
ggplot(student, aes(x = guardian, fill = guardian)) +
geom_bar() +
labs(title = "Primary Caregiver Distribution",
x = "Guardian", y = "Count")
library(ggplot2)
ggplot(student, aes(x = G1)) +
geom_histogram(binwidth = 1, fill = "pink", color = "black") +
labs(title = "Distribution of G1 (First Trimester Grades)", x = "G1", y = "Count")
ggplot(student, aes(x = G2)) +
geom_histogram(binwidth = 1, fill = "lavender", color = "black") +
labs(title = "Distribution of G2 (Second Trimester Grades)", x = "G2", y = "Count")
ggplot(student, aes(x = G3)) +
geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
labs(title = "Distribution of G3 (Final Grades)", x = "G3", y = "Count")
cor(student[, c("G1", "G2", "G3")])
# Create a recipe for preprocessing
student_pca_recipe <- recipe(G3 ~ ., data = student_train) |>
step_dummy(all_nominal_predictors()) |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors())
#categorizing
student_multinom_data <- student_train |>
mutate(G3_category = case_when(
G3 < 10 ~ "low",         # Failing or poor performance
G3 >= 10 & G3 < 15 ~ "medium",  # Average performance
G3 >= 15 ~ "high"        # High-performing students
))
pca_scores <- as.data.frame(student_pca_model$x[, 1:2])  # PC1 and PC2
pca_scores$G3_category <- student_multinom_data$G3_category
# Coefficients
summary(multinom_model)$coefficients
# Z-scores and p-values
z <- summary(multinom_model)$coefficients / summary(multinom_model)$standard.errors
p <- 2 * (1 - pnorm(abs(z)))
p
