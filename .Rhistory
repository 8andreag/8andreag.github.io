geom_smooth(method = "lm", se = FALSE, color = "blue") +
facet_wrap(~ Term) +
labs(title = "Father's Education vs. Final Grades",
x = "Father's Education Level",
y = "Final Grades")
ggplot(student_G123,
mapping = aes(
x = Medu,
y = Grade,
color = sex
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
facet_wrap(~ Term) +
labs(title = "Mother's Education vs. Final Grades",
x = "Mother's Education Level",
y = "Final Grades")
ggplot(data = student_G123,
mapping = aes(
x = studytime,
y = Grade,
fill = sex
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Study Times Across Terms",
x = "Study Time",
y = "Grade")
student_G123 |>
group_by(sex, Term) |>
summarise(
num_total = n(),
min = min(Grade, na.rm = TRUE),
median = median(Grade, na.rm = TRUE),
max = max(Grade, na.rm = TRUE),
mean = mean(Grade, na.rm = TRUE),
sd = sd(Grade, na.rm = TRUE)
)
summary(student_train$studytime)
ggplot(data = student_train,
mapping = aes(
x = studytime,
fill = sex
)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Study Time", x = "Study Time (1 = <2 hours, 4 = >10 hours)", y = "Count")
summary(student$Pstatus)
table(student$Pstatus)
ggplot(student, aes(x = Pstatus, fill = Pstatus)) +
geom_bar() +
labs(title = "Distribution of Parental Cohabitation Status",
x = "Pstatus (T = together, A = apart)", y = "Count")
summary(student$guardian)
table(student$guardian)
ggplot(student, aes(x = guardian, fill = guardian)) +
geom_bar() +
labs(title = "Primary Caregiver Distribution",
x = "Guardian", y = "Count")
summary(student$schoolsup)
table(student$schoolsup)
ggplot(student, aes(x = schoolsup, fill = schoolsup)) +
geom_bar() +
labs(title = "Extra Educational Support at School",
x = "School Support", y = "Count")
summary(student$health)
table(student$health)
ggplot(student, aes(x = health)) +
geom_histogram(binwidth = 1, fill = "orange", color = "black") +
labs(title = "Distribution of Health Ratings",
x = "Health (1 = very bad, 5 = very good)", y = "Count")
summary(student$absences)
ggplot(student, aes(x = absences)) +
geom_histogram(binwidth = 1, fill = "lightgreen", color = "black") +
coord_cartesian(xlim = c(0, 30)) +  # Optional: zoom in on the more common range
labs(title = "Distribution of School Absences",
x = "Number of Absences", y = "Count")
summary(student_train$G1)
summary(student_train$G2)
summary(student_train$G3)
library(ggplot2)
ggplot(student, aes(x = G1)) +
geom_histogram(binwidth = 1, fill = "pink", color = "black") +
labs(title = "Distribution of G1 (First Trimester Grades)", x = "G1", y = "Count")
ggplot(student, aes(x = G2)) +
geom_histogram(binwidth = 1, fill = "lavender", color = "black") +
labs(title = "Distribution of G2 (Second Trimester Grades)", x = "G2", y = "Count")
ggplot(student, aes(x = G3)) +
geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
labs(title = "Distribution of G3 (Final Grades)", x = "G3", y = "Count")
cor(student[, c("G1", "G2", "G3")])
ggplot(student, aes(x = G1, y = G3)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(title = "G1 vs. G3", x = "G1", y = "G3 (Final Grade)")
ggplot(student, aes(x = G2, y = G3)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, color = "darkred") +
labs(title = "G2 vs. G3", x = "G2", y = "G3 (Final Grade)")
# Create a recipe for preprocessing
student_pca_recipe <- recipe(~ ., data = student_train) |>
# Remove response variable(s) if using G3 for later comparison
update_role(G3, new_role = "outcome") |> #Redefines the role of G3 as the response.
step_dummy(all_nominal_predictors()) |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors())
#This step learns everything needed to transform the training data.
student_pca_prep <- student_pca_recipe |>
prep() #prepares the recipe by estimating means and standard deviations (from step_center, step_scale) and fitting the one-hot encodings.
student_pca_baked <- bake(student_pca_prep, new_data = NULL)
#bake() applies the recipe (centered, scaled, dummified) to the training data.
#new_data = NULL means it’s applying the recipe to the original training set used in prep().
# Apply PCA
student_pca_model <- prcomp(student_pca_baked, center = TRUE, scale. = TRUE)
#Runs Principal Component Analysis on your preprocessed dataset using prcomp().
#center = TRUE and scale. = TRUE are technically redundant here (you already centered/scaled via the recipe), but it doesn’t hurt.
student_pca_pve <- student_pca_model |>
tidy(matrix = "pcs")
ggplot(student_pca_pve,
aes(x = PC, y = percent)) +
geom_point() +
geom_line() +
labs(x = "Number of PCs",
y = "Proportion of Variance Explained")
ggplot(student_pca_pve,
aes(x = PC, y = cumulative)) +
geom_point() +
geom_line() +
geom_hline(yintercept = 0.8, color = "red") +
labs(x = "Number of PCs",
y = "Cumulative Proportion of Variance Explained")
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 2)
ggplot(student_pve_tidy |>
filter(terms == "percent variance"),
aes(
x = component,
y = value
)) +
geom_point() +
geom_line() +
labs(x = "Number of PC's",
y = "Percent Variance Explained")
rlang::last_trace()
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 6)
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 2)
ggplot(student_pve_tidy |>
filter(terms == "percent variance"),
aes(
x = component,
y = value
)) +
geom_point() +
geom_line() +
labs(x = "Number of PC's",
y = "Percent Variance Explained")
student_pve_tidy
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 2)
ggplot(student_pve_tidy |>
filter(terms == "percent variance"),
aes(
x = id,
y = value
)) +
geom_point() +
geom_line() +
labs(x = "Number of PC's",
y = "Percent Variance Explained")
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 2)
ggplot(student_pve_tidy |>
filter(terms == "percent variance"),
aes(
x = id,
y = value
)) +
geom_point() +
geom_line() +
labs(x = "Number of PC's",
y = "Percent Variance Explained")
student_pve_tidy <- tidy(student_pca_prep, type = "variance")
ggplot(student_pve_tidy |>
filter(terms == "percent variance"),
aes(
x = id,
y = value
)) +
geom_point() +
geom_line() +
labs(x = "Number of PC's",
y = "Percent Variance Explained")
student_pve_tidy
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 2)
ggplot(student_pve_tidy |>
filter(terms == "percent variance"),
aes(
x = id,
y = value
)) +
geom_point() +
geom_line() +
labs(x = "Number of PC's",
y = "Percent Variance Explained")
student_pve_tidy
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 2)
here::i_am("437proj.qmd")
#| label: load packages
#| message: false
#| warning: false
library(here)
library(readr)
library(dplyr)
library(ggplot2)
library(rsample)
library(tidymodels)
library(tidyverse)
library(recipes) # don't need the rest of tidymodels
library(naniar)
library(softImpute)
library(broom)
library(mice)
#| label: import data
#| warning: false
data <- readr::read_csv(here::here("student-por.csv"))
data
vis_miss(data[,1:33]) # default row and column order
student <- data |>
select(sex, Pstatus, Fedu, Medu, guardian, studytime, schoolsup, famsup, health, absences, G1, G2, G3)
student <- student |>
mutate(
sex = as.factor(sex),
Pstatus = as.factor(Pstatus),
guardian = as.factor(guardian),
studytime = as.factor(studytime),
schoolsup = as.factor(schoolsup),
famsup = as.factor(famsup)
)
student
set.seed(123)
student_split <- initial_split(data, prop = 0.80)  #splitting data  (random sample, 80%)
student_train <- training(student_split)
student_test <- testing(student_split)
student_train |>
miss_var_summary()
table(student_train$famsup)
ggplot(data = student_train,
mapping = aes(
x = famsup,
fill = famsup
)
) +
geom_bar(binwidth = 1) +
labs(title = "Distribution of Family Support", x = "Family Support", y = "Count")
student_G123 <- student_train |>
pivot_longer(cols = c(G1, G2, G3),
names_to = "Term",
values_to = "Grade")
ggplot(student_G123,
mapping = aes(
x = famsup,
y = Grade,
fill = famsup
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Family Support Across Terms",
x = "Family Support",
y = "Grade")
summary(student_train$G1)
summary(student_train$G2)
summary(student_train$G3)
ggplot(data = student_G123,
mapping = aes(
x = Grade,
fill = famsup)
) +
geom_histogram(binwidth = 1) +
facet_grid(
rows = vars(famsup), cols = vars(Term)
)
summary(student_train$Fedu)
ggplot(data = student_G123,
mapping = aes(
x = Fedu
)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Father's Education", x = "Education Level", y = "Count")
summary(student_train$Medu)
ggplot(data = student_G123,
mapping = aes(
x = Medu
)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Mother's Education", x = "Education Level", y = "Count")
ggplot(student_G123,
mapping = aes(
x = Fedu,
y = Grade,
color = sex
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
facet_wrap(~ Term) +
labs(title = "Father's Education vs. Final Grades",
x = "Father's Education Level",
y = "Final Grades")
ggplot(student_G123,
mapping = aes(
x = Medu,
y = Grade,
color = sex
)
) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
facet_wrap(~ Term) +
labs(title = "Mother's Education vs. Final Grades",
x = "Mother's Education Level",
y = "Final Grades")
ggplot(data = student_G123,
mapping = aes(
x = studytime,
y = Grade,
fill = sex
)
) +
geom_boxplot() +
facet_wrap(~ Term) +
labs(title = "Grade Distribution by Study Times Across Terms",
x = "Study Time",
y = "Grade")
student_G123 |>
group_by(sex, Term) |>
summarise(
num_total = n(),
min = min(Grade, na.rm = TRUE),
median = median(Grade, na.rm = TRUE),
max = max(Grade, na.rm = TRUE),
mean = mean(Grade, na.rm = TRUE),
sd = sd(Grade, na.rm = TRUE)
)
summary(student_train$studytime)
ggplot(data = student_train,
mapping = aes(
x = studytime,
fill = sex
)
) +
geom_histogram(binwidth = 1) +
labs(title = "Distribution of Study Time", x = "Study Time (1 = <2 hours, 4 = >10 hours)", y = "Count")
summary(student$Pstatus)
table(student$Pstatus)
ggplot(student, aes(x = Pstatus, fill = Pstatus)) +
geom_bar() +
labs(title = "Distribution of Parental Cohabitation Status",
x = "Pstatus (T = together, A = apart)", y = "Count")
summary(student$guardian)
table(student$guardian)
ggplot(student, aes(x = guardian, fill = guardian)) +
geom_bar() +
labs(title = "Primary Caregiver Distribution",
x = "Guardian", y = "Count")
summary(student$schoolsup)
table(student$schoolsup)
ggplot(student, aes(x = schoolsup, fill = schoolsup)) +
geom_bar() +
labs(title = "Extra Educational Support at School",
x = "School Support", y = "Count")
summary(student$health)
table(student$health)
ggplot(student, aes(x = health)) +
geom_histogram(binwidth = 1, fill = "orange", color = "black") +
labs(title = "Distribution of Health Ratings",
x = "Health (1 = very bad, 5 = very good)", y = "Count")
summary(student$absences)
ggplot(student, aes(x = absences)) +
geom_histogram(binwidth = 1, fill = "lightgreen", color = "black") +
coord_cartesian(xlim = c(0, 30)) +  # Optional: zoom in on the more common range
labs(title = "Distribution of School Absences",
x = "Number of Absences", y = "Count")
summary(student_train$G1)
summary(student_train$G2)
summary(student_train$G3)
library(ggplot2)
ggplot(student, aes(x = G1)) +
geom_histogram(binwidth = 1, fill = "pink", color = "black") +
labs(title = "Distribution of G1 (First Trimester Grades)", x = "G1", y = "Count")
ggplot(student, aes(x = G2)) +
geom_histogram(binwidth = 1, fill = "lavender", color = "black") +
labs(title = "Distribution of G2 (Second Trimester Grades)", x = "G2", y = "Count")
ggplot(student, aes(x = G3)) +
geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
labs(title = "Distribution of G3 (Final Grades)", x = "G3", y = "Count")
cor(student[, c("G1", "G2", "G3")])
ggplot(student, aes(x = G1, y = G3)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, color = "blue") +
labs(title = "G1 vs. G3", x = "G1", y = "G3 (Final Grade)")
ggplot(student, aes(x = G2, y = G3)) +
geom_point(alpha = 0.5) +
geom_smooth(method = "lm", se = FALSE, color = "darkred") +
labs(title = "G2 vs. G3", x = "G2", y = "G3 (Final Grade)")
# Create a recipe for preprocessing
student_pca_recipe <- recipe(~ ., data = student_train) |>
# Remove response variable(s) if using G3 for later comparison
update_role(G3, new_role = "outcome") |> #Redefines the role of G3 as the response.
step_dummy(all_nominal_predictors()) |>
step_center(all_numeric_predictors()) |>
step_scale(all_numeric_predictors())
#This step learns everything needed to transform the training data.
student_pca_prep <- student_pca_recipe |>
prep() #prepares the recipe by estimating means and standard deviations (from step_center, step_scale) and fitting the one-hot encodings.
student_pca_baked <- bake(student_pca_prep, new_data = NULL)
#bake() applies the recipe (centered, scaled, dummified) to the training data.
#new_data = NULL means it’s applying the recipe to the original training set used in prep().
# Apply PCA
student_pca_model <- prcomp(student_pca_baked, center = TRUE, scale. = TRUE)
#Runs Principal Component Analysis on your preprocessed dataset using prcomp().
#center = TRUE and scale. = TRUE are technically redundant here (you already centered/scaled via the recipe), but it doesn’t hurt.
student_pca_pve <- student_pca_model |>
tidy(matrix = "pcs")
ggplot(student_pca_pve,
aes(x = PC, y = percent)) +
geom_point() +
geom_line() +
labs(x = "Number of PCs",
y = "Proportion of Variance Explained")
ggplot(student_pca_pve,
aes(x = PC, y = cumulative)) +
geom_point() +
geom_line() +
geom_hline(yintercept = 0.8, color = "red") +
labs(x = "Number of PCs",
y = "Cumulative Proportion of Variance Explained")
student_pve_tidy <- tidy(student_pca_prep, type = "variance", number = 2)
ggplot(student_pve_tidy |>
filter(terms == "percent variance"),
aes(
x = id,
y = value
)) +
geom_point() +
geom_line() +
labs(x = "Number of PC's",
y = "Percent Variance Explained")
set.seed(123)
rownames(student_pca$x) <- cstudent$G3
set.seed(123)
rownames(student_pca$x) <- student$G3
set.seed(123)
rownames(student_pca_model$x) <- student$G3
set.seed(123)
biplot(pca_model,
scale = 0,
cex = 0.6,            # Shrinks text size for better readability
main = "Base R PCA Biplot")
set.seed(123)
biplot(student_pca_model,
scale = 0,
cex = 0.6,            # Shrinks text size for better readability
main = "Base R PCA Biplot")
student_pca_model
ggplot(student_pca_pve,
aes(x = PC, y = cumulative)) +
geom_point() +
geom_line() +
geom_hline(yintercept = 0.8, color = "red") +
labs(x = "Number of PCs",
y = "Cumulative Proportion of Variance Explained")
which(explained_var >= 0.80)[1]
ggplot(student_pca_pve,
aes(x = PC, y = cumulative)) +
geom_point() +
geom_line() +
geom_hline(yintercept = 0.8, color = "red") +
labs(x = "Number of PCs",
y = "Cumulative Proportion of Variance Explained")
explained_var <- summary(student_pca_model)$importance[3, ]
which(explained_var >= 0.80)[1]
ggplot(student_pca_pve,
aes(x = PC, y = cumulative)) +
geom_point() +
geom_line() +
geom_hline(yintercept = 0.8, color = "red") +
labs(x = "Number of PCs",
y = "Cumulative Proportion of Variance Explained")
explained_var <- summary(student_pca_model)$importance[3, ]
which(explained_var >= 0.80)[1]
summary(student_pca_model)$importance
plot(student_pca_model, type = "l", main = "Scree Plot")
plot(student_pca_model, type = "l", main = "Scree Plot")
cum_var <- cumsum(student_pca_model$sdev^2) / sum(pca_model$sdev^2)
plot(student_pca_model, type = "l", main = "Scree Plot")
cum_var <- cumsum(student_pca_model$sdev^2) / sum(student_pca_model$sdev^2)
plot(student_pca_model, type = "l", main = "Scree Plot")
cum_var <- cumsum(student_pca_model$sdev^2) / sum(student_pca_model$sdev^2)
plot(cum_var, type = "b", xlab = "Number of Components",
ylab = "Cumulative Variance Explained",
main = "Cumulative Variance Explained")
abline(h = 0.8, col = "blue", lty = 2)
pca_2dim <- as.data.frame(student_pca_model$x[, 1:2])  # Keep only PC1 and PC2
colnames(pca_2dim) <- c("PC1", "PC2")
pca_2dim <- cbind(pca_2dim, cluster = student_clustered$cluster)
set.seed(123)
biplot(student_pca_model,
scale = 0,
cex = 0.6,            # Shrinks text size for better readability
main = "Base R PCA Biplot")
